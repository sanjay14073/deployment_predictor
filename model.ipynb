{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24397a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in ./.venv/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: statsmodels in ./.venv/lib/python3.13/site-packages (0.14.5)\n",
      "Requirement already satisfied: prophet in ./.venv/lib/python3.13/site-packages (1.1.7)\n",
      "Requirement already satisfied: tabulate in ./.venv/lib/python3.13/site-packages (0.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: patsy>=0.5.6 in ./.venv/lib/python3.13/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in ./.venv/lib/python3.13/site-packages (from prophet) (1.2.5)\n",
      "Requirement already satisfied: holidays<1,>=0.25 in ./.venv/lib/python3.13/site-packages (from prophet) (0.82)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in ./.venv/lib/python3.13/site-packages (from prophet) (4.67.1)\n",
      "Requirement already satisfied: importlib_resources in ./.venv/lib/python3.13/site-packages (from prophet) (6.5.2)\n",
      "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in ./.venv/lib/python3.13/site-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn matplotlib seaborn statsmodels prophet tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8317c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanjaym/Desktop/projects/simple_ml_predictor/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d2c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 744\n"
     ]
    }
   ],
   "source": [
    "# Load CSV (do not use index_col so all columns are available)\n",
    "df = pd.read_csv('data/data.csv')\n",
    "print('Rows:', len(df))\n",
    "df.head()\n",
    "\n",
    "# Prepare hourly time series DataFrame\n",
    "df_hourly = df.groupby(['date', 'hour'])[['number_of_transactions', 'total_amount']].sum().reset_index()\n",
    "\n",
    "# construct a datetime 'ds' column\n",
    "df_hourly['ds'] = pd.to_datetime(df_hourly['date'].astype(str) + ' ' + df_hourly['hour'].astype(str) + ':00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9413a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Variable 'y' Head (Weighted Impact Score):\n",
      "                   ds         y\n",
      "0 2024-01-01 00:00:00  0.033140\n",
      "1 2024-01-01 01:00:00  0.008085\n",
      "2 2024-01-01 02:00:00  0.017125\n",
      "3 2024-01-01 03:00:00  0.024624\n",
      "4 2024-01-01 04:00:00  0.008839\n"
     ]
    }
   ],
   "source": [
    "# 1. Normalize the two impact columns (Min-Max Scaling)\n",
    "min_tx = df_hourly['number_of_transactions'].min()\n",
    "max_tx = df_hourly['number_of_transactions'].max()\n",
    "# Handle case where min == max (to avoid division by zero)\n",
    "range_tx = max_tx - min_tx\n",
    "df_hourly['norm_transactions'] = (df_hourly['number_of_transactions'] - min_tx) / range_tx if range_tx != 0 else 0\n",
    "\n",
    "min_amt = df_hourly['total_amount'].min()\n",
    "max_amt = df_hourly['total_amount'].max()\n",
    "range_amt = max_amt - min_amt\n",
    "df_hourly['norm_amount'] = (df_hourly['total_amount'] - min_amt) / range_amt if range_amt != 0 else 0\n",
    "\n",
    "\n",
    "# 2. Apply the 60:40 weighting to the normalized values to create the target variable 'y'\n",
    "# 60% weight on normalized transactions, 40% on normalized amount.\n",
    "WEIGHT_TX = 0.60\n",
    "WEIGHT_AMT = 0.40\n",
    "df_hourly['y'] = (df_hourly['norm_transactions'] * WEIGHT_TX) + (df_hourly['norm_amount'] * WEIGHT_AMT)\n",
    "\n",
    "# Select the necessary columns for Prophet\n",
    "df_ts = df_hourly[['ds', 'y']].sort_values('ds').reset_index(drop=True)\n",
    "print(\"\\nTarget Variable 'y' Head (Weighted Impact Score):\")\n",
    "print(df_ts.head())\n",
    "\n",
    "# Feature engineering (exogenous regressors)\n",
    "df_features = df_ts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c65e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original rows: 744, After lag & dropna: 576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_24h</th>\n",
       "      <th>lag_168h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-08 00:00:00</td>\n",
       "      <td>0.033041</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>0.033140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-08 01:00:00</td>\n",
       "      <td>0.033432</td>\n",
       "      <td>8</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033264</td>\n",
       "      <td>0.008085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-08 02:00:00</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041221</td>\n",
       "      <td>0.017125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-08 03:00:00</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>8</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.024624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-08 04:00:00</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>8</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024621</td>\n",
       "      <td>0.008839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ds         y  day_of_month  hour_sin  hour_cos  day_sin  \\\n",
       "0 2024-01-08 00:00:00  0.033041             8  0.000000  1.000000      0.0   \n",
       "1 2024-01-08 01:00:00  0.033432             8  0.258819  0.965926      0.0   \n",
       "2 2024-01-08 02:00:00  0.042954             8  0.500000  0.866025      0.0   \n",
       "3 2024-01-08 03:00:00  0.048875             8  0.707107  0.707107      0.0   \n",
       "4 2024-01-08 04:00:00  0.008804             8  0.866025  0.500000      0.0   \n",
       "\n",
       "   day_cos  is_weekend   lag_24h  lag_168h  \n",
       "0      1.0           0  0.025796  0.033140  \n",
       "1      1.0           0  0.033264  0.008085  \n",
       "2      1.0           0  0.041221  0.017125  \n",
       "3      1.0           0  0.008341  0.024624  \n",
       "4      1.0           0  0.024621  0.008839  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A. Cyclical and Binary Features\n",
    "df_features['hour'] = df_features['ds'].dt.hour\n",
    "df_features['day_of_week'] = df_features['ds'].dt.dayofweek # Mon=0, Sun=6\n",
    "df_features['day_of_month'] = df_features['ds'].dt.day # Regressor for monthly cycles\n",
    "\n",
    "# Cyclical Encoding for Hour (24-hour cycle)\n",
    "df_features['hour_sin'] = np.sin(2 * np.pi * df_features['hour'] / 24)\n",
    "df_features['hour_cos'] = np.cos(2 * np.pi * df_features['hour'] / 24)\n",
    "\n",
    "# Cyclical Encoding for Day of Week (7-day cycle)\n",
    "df_features['day_sin'] = np.sin(2 * np.pi * df_features['day_of_week'] / 7)\n",
    "df_features['day_cos'] = np.cos(2 * np.pi * df_features['day_of_week'] / 7)\n",
    "\n",
    "# Is it a Weekend?\n",
    "df_features['is_weekend'] = df_features['day_of_week'].isin([5,6]).astype(int)\n",
    "\n",
    "# Drop temporary raw columns\n",
    "df_features = df_features.drop(columns=['hour','day_of_week'])\n",
    "\n",
    "# Add lag features for daily and weekly seasonality\n",
    "df_features['lag_24h'] = df_features['y'].shift(24)\n",
    "df_features['lag_168h'] = df_features['y'].shift(168)\n",
    "\n",
    "# Drop initial rows with NaNs from lags\n",
    "df_prepared = df_features.dropna().reset_index(drop=True)\n",
    "print(f'\\nOriginal rows: {len(df_ts)}, After lag & dropna: {len(df_prepared)}')\n",
    "df_prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f216694d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "03:06:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 408 rows.\n",
      "Testing set size: 168 rows (168 hours).\n",
      "\n",
      "Model Evaluation on Test Data:\n",
      "Mean Absolute Error (MAE): 0.0695\n",
      "Root Mean Squared Error (RMSE): 0.0954\n"
     ]
    }
   ],
   "source": [
    "# Train / test split: use 7 days (one week) for test since the dataset is one month long\n",
    "TEST_SIZE = 7 * 24\n",
    "if TEST_SIZE >= len(df_prepared):\n",
    "    TEST_SIZE = max(24, len(df_prepared) // 5)  # fallback: 20% or at least 24 hours\n",
    "df_train = df_prepared.iloc[:-TEST_SIZE].reset_index(drop=True)\n",
    "df_test = df_prepared.iloc[-TEST_SIZE:].reset_index(drop=True)\n",
    "print(f'\\nTraining set size: {len(df_train)} rows.')\n",
    "print(f'Testing set size: {len(df_test)} rows ({TEST_SIZE} hours).')\n",
    "\n",
    "# Fit Prophet with all exogenous regressors, including the new 'day_of_month'\n",
    "model = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=False, interval_width=0.95)\n",
    "exogenous_features = [\n",
    "    'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend',\n",
    "    'lag_24h', 'lag_168h', 'day_of_month' # <<< New feature added\n",
    "]\n",
    "\n",
    "for feature in exogenous_features:\n",
    "    model.add_regressor(feature)\n",
    "\n",
    "# Prophet expects columns: ds, y, and the added regressor columns in the training DataFrame\n",
    "model.fit(df_train[['ds','y'] + exogenous_features])\n",
    "\n",
    "# --- Evaluation (using the test set) ---\n",
    "df_future_test = df_test[['ds'] + exogenous_features].copy()\n",
    "forecast_test = model.predict(df_future_test)\n",
    "y_pred = forecast_test['yhat'].values\n",
    "y_true = df_test['y'].values\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "print('\\nModel Evaluation on Test Data:')\n",
    "print(f'Mean Absolute Error (MAE): {mae:,.4f}') # Increased precision since 'y' is now normalized\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:,.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c787927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanjaym/Desktop/projects/simple_ml_predictor/.venv/lib/python3.13/site-packages/prophet/forecaster.py:1872: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  dates = pd.date_range(\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Future Forecast for Next Month (30 days) ---\n",
    "FUTURE_DAYS = 30\n",
    "future = model.make_future_dataframe(periods=FUTURE_DAYS * 24, freq='H')\n",
    "\n",
    "# 1. Populate the exogenous features for the future period\n",
    "future['hour'] = future['ds'].dt.hour\n",
    "future['day_of_week'] = future['ds'].dt.dayofweek\n",
    "future['day_of_month'] = future['ds'].dt.day # New Regressor for monthly cycles\n",
    "\n",
    "future['hour_sin'] = np.sin(2 * np.pi * future['hour'] / 24)\n",
    "future['hour_cos'] = np.cos(2 * np.pi * future['hour'] / 24)\n",
    "future['day_sin'] = np.sin(2 * np.pi * future['day_of_week'] / 7)\n",
    "future['day_cos'] = np.cos(2 * np.pi * future['day_of_week'] / 7)\n",
    "future['is_weekend'] = future['day_of_week'].isin([5,6]).astype(int)\n",
    "\n",
    "# 2. Populate the Lag Features for the future period\n",
    "# Propagating historical lags and filling the recursive steps with the mean.\n",
    "mean_y = df_prepared['y'].mean()\n",
    "future['lag_24h'] = future['ds'].apply(lambda x: df_prepared[df_prepared['ds'] == (x - pd.Timedelta(hours=24))]['y'].values[0] if (x - pd.Timedelta(hours=24)) in df_prepared['ds'].values else np.nan)\n",
    "future['lag_168h'] = future['ds'].apply(lambda x: df_prepared[df_prepared['ds'] == (x - pd.Timedelta(hours=168))]['y'].values[0] if (x - pd.Timedelta(hours=168)) in df_prepared['ds'].values else np.nan)\n",
    "\n",
    "future['lag_24h'] = future['lag_24h'].fillna(mean_y)\n",
    "future['lag_168h'] = future['lag_168h'].fillna(mean_y)\n",
    "\n",
    "# Filter the future DataFrame to only include the *new* 30 days\n",
    "start_of_forecast = df_prepared['ds'].max() + pd.Timedelta(hours=1)\n",
    "future_forecast = future[future['ds'] >= start_of_forecast].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. Generate the 30-Day Forecast\n",
    "forecast_30d = model.predict(future_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c22e37a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- 30-DAY DEPLOYMENT RISK ANALYSIS & RECOMMENDATIONS ---\n",
      "\n",
      "[A] GLOBAL MINIMUM RISK DEPLOYMENT WINDOW (The Absolute Safest Hour)\n",
      "Date/Time: 2024-02-01 01:00:00\n",
      "Day of Week: Thursday\n",
      "Predicted Impact (Norm): 0.5157\n",
      "Minimum Risk Score: 0.8870\n",
      "This is the hour with the lowest combination of predicted traffic and uncertainty in the entire month.\n",
      "\n",
      "[B] GLOBAL MAXIMUM RISK DEPLOYMENT WINDOW (The Absolute Riskiest Hour)\n",
      "Date/Time: 2024-02-01 17:00:00\n",
      "Day of Week: Thursday\n",
      "Predicted Impact (Norm): 1.1430\n",
      "Maximum Risk Score: 1.5366\n",
      "Deploying during this hour carries the highest combined traffic and uncertainty risk.\n",
      "\n",
      "[C] TOP 5 LOW-RISK DEPLOYMENT WINDOWS (Next Best Suggestions)\n",
      "Based on the 60:40 weighted impact score (normalized 0 to 1).\n",
      "| Date_Time           | Day_of_Week   |   Hour |   Predicted_Impact (Norm) |   Risk_Score |\n",
      "|:--------------------|:--------------|-------:|--------------------------:|-------------:|\n",
      "| 2024-02-01 01:00:00 | Thursday      |      1 |                    0.5157 |       0.8870 |\n",
      "| 2024-02-01 03:00:00 | Thursday      |      3 |                    0.5282 |       0.9096 |\n",
      "| 2024-02-01 02:00:00 | Thursday      |      2 |                    0.5102 |       0.9161 |\n",
      "| 2024-02-01 00:00:00 | Thursday      |      0 |                    0.5371 |       0.9197 |\n",
      "| 2024-02-01 04:00:00 | Thursday      |      4 |                    0.5473 |       0.9342 |\n",
      "\n",
      "[D] RISK ANALYSIS BY DATE OF MONTH (Where 1 is the riskiest day - Mean Risk)\n",
      "|   Rank |   Day_of_Month |   Risk_Score |\n",
      "|-------:|---------------:|-------------:|\n",
      "| 1.0000 |        18.0000 |       1.2122 |\n",
      "| 2.0000 |        11.0000 |       1.2066 |\n",
      "| 3.0000 |         4.0000 |       1.2049 |\n",
      "| 4.0000 |        17.0000 |       1.1942 |\n",
      "| 5.0000 |         3.0000 |       1.1908 |\n",
      "\n",
      "[E] RISK ANALYSIS BY DAY OF WEEK (Where 1 is the riskiest day - Mean Risk)\n",
      "|   Rank | Day_of_Week   |   Risk_Score |\n",
      "|-------:|:--------------|-------------:|\n",
      "|      7 | Monday        |       1.1552 |\n",
      "|      4 | Tuesday       |       1.1752 |\n",
      "|      6 | Wednesday     |       1.1648 |\n",
      "|      3 | Thursday      |       1.1796 |\n",
      "|      5 | Friday        |       1.1674 |\n",
      "|      2 | Saturday      |       1.1914 |\n",
      "|      1 | Sunday        |       1.2079 |\n",
      "\n",
      "[F] RISK ANALYSIS BY HOUR OF DAY (Where 1 is the riskiest hour - Mean Risk)\n",
      "|    Rank |    Hour |   Risk_Score |\n",
      "|--------:|--------:|-------------:|\n",
      "|  1.0000 | 18.0000 |       1.3881 |\n",
      "|  2.0000 | 19.0000 |       1.3729 |\n",
      "|  3.0000 | 17.0000 |       1.3557 |\n",
      "|  4.0000 | 20.0000 |       1.3253 |\n",
      "|  5.0000 | 16.0000 |       1.2736 |\n",
      "|  6.0000 | 12.0000 |       1.2507 |\n",
      "|  7.0000 | 11.0000 |       1.2485 |\n",
      "|  8.0000 | 13.0000 |       1.2251 |\n",
      "|  9.0000 | 15.0000 |       1.2229 |\n",
      "| 10.0000 | 10.0000 |       1.2219 |\n",
      "| 11.0000 | 21.0000 |       1.2208 |\n",
      "| 12.0000 | 14.0000 |       1.2124 |\n",
      "| 13.0000 |  9.0000 |       1.1844 |\n",
      "| 14.0000 | 22.0000 |       1.1425 |\n",
      "| 15.0000 |  8.0000 |       1.1302 |\n",
      "| 16.0000 |  7.0000 |       1.1057 |\n",
      "| 17.0000 | 23.0000 |       1.0943 |\n",
      "| 18.0000 |  6.0000 |       1.0921 |\n",
      "| 19.0000 |  5.0000 |       1.0739 |\n",
      "| 20.0000 |  4.0000 |       1.0419 |\n",
      "| 21.0000 |  0.0000 |       1.0301 |\n",
      "| 22.0000 |  3.0000 |       1.0148 |\n",
      "| 23.0000 |  1.0000 |       1.0115 |\n",
      "| 24.0000 |  2.0000 |       1.0092 |\n",
      "\n",
      "[G] RISK ANALYSIS BY HOUR AND DAY COMBINED (Where 1 is the riskiest window - Mean Risk)\n",
      "This table ranks all 168 weekly hourly windows (Day + Hour) by their average risk score.\n",
      "\n",
      "Top 10 Riskiest Windows:\n",
      "|   Rank | Day_of_Week   |   Hour |   Risk_Score |\n",
      "|-------:|:--------------|-------:|-------------:|\n",
      "|      1 | Sunday        |     18 |       1.4199 |\n",
      "|      2 | Thursday      |     18 |       1.4162 |\n",
      "|      3 | Saturday      |     19 |       1.4038 |\n",
      "|      4 | Sunday        |     19 |       1.4007 |\n",
      "|      5 | Thursday      |     19 |       1.3977 |\n",
      "|      6 | Saturday      |     18 |       1.3964 |\n",
      "|      7 | Sunday        |     17 |       1.3890 |\n",
      "|      8 | Tuesday       |     18 |       1.3832 |\n",
      "|      9 | Thursday      |     17 |       1.3797 |\n",
      "|     10 | Saturday      |     17 |       1.3797 |\n",
      "\n",
      "Top 10 Safest Windows:\n",
      "|   Rank | Day_of_Week   |   Hour |   Risk_Score |\n",
      "|-------:|:--------------|-------:|-------------:|\n",
      "|    168 | Monday        |      3 |       0.9870 |\n",
      "|    167 | Monday        |      2 |       0.9884 |\n",
      "|    166 | Thursday      |      2 |       0.9894 |\n",
      "|    165 | Monday        |      1 |       0.9894 |\n",
      "|    164 | Thursday      |      1 |       0.9926 |\n",
      "|    163 | Thursday      |      3 |       0.9984 |\n",
      "|    162 | Monday        |      0 |       0.9987 |\n",
      "|    161 | Saturday      |      2 |       1.0000 |\n",
      "|    160 | Tuesday       |      1 |       1.0047 |\n",
      "|    159 | Tuesday       |      3 |       1.0085 |\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Risk: Risk increases with predicted impact (yhat) and with uncertainty (yhat_upper - yhat_lower)\n",
    "forecast_30d['Uncertainty_Band'] = forecast_30d['yhat_upper'] - forecast_30d['yhat_lower']\n",
    "\n",
    "# Calculate a Risk Score: High predicted volume + High uncertainty = High Risk\n",
    "# Risk Score = (Predicted Impact) + (Uncertainty Band)\n",
    "forecast_30d['Risk_Score'] = forecast_30d['yhat'] + forecast_30d['Uncertainty_Band']\n",
    "\n",
    "# 2. Extract key time components for analysis\n",
    "forecast_30d['Hour'] = forecast_30d['ds'].dt.hour\n",
    "forecast_30d['Date'] = forecast_30d['ds'].dt.strftime('%Y-%m-%d')\n",
    "forecast_30d['Day_of_Week'] = forecast_30d['ds'].dt.day_name()\n",
    "forecast_30d['Day_of_Month'] = forecast_30d['ds'].dt.day\n",
    "\n",
    "# 3. Find Global Minimum and Maximum Risk Hours\n",
    "min_risk_hour = forecast_30d.sort_values('Risk_Score', ascending=True).iloc[0]\n",
    "max_risk_hour = forecast_30d.sort_values('Risk_Score', ascending=False).iloc[0]\n",
    "\n",
    "# 4. Find Top 5 Deployment Windows (Lowest Risk)\n",
    "recommendations = forecast_30d.sort_values('Risk_Score', ascending=True).head(5)\n",
    "recommendations = recommendations[['ds', 'Day_of_Week', 'Hour', 'yhat', 'Risk_Score']].copy()\n",
    "recommendations.columns = ['Date_Time', 'Day_of_Week', 'Hour', 'Predicted_Impact (Norm)', 'Risk_Score']\n",
    "\n",
    "# 5. Analyze Risk by Hour of Day\n",
    "risk_by_hour = forecast_30d.groupby('Hour')['Risk_Score'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# 6. Analyze Risk by Date of Month and Day of Week\n",
    "risk_by_month_day = forecast_30d.groupby('Day_of_Month')['Risk_Score'].mean().sort_values(ascending=False).reset_index()\n",
    "risk_by_day_of_week = forecast_30d.groupby('Day_of_Week')['Risk_Score'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# 7. Analyze Risk by Hour and Day Combined\n",
    "risk_by_hour_day = forecast_30d.groupby(['Day_of_Week', 'Hour'])['Risk_Score'].mean().sort_values(ascending=False).reset_index()\n",
    "risk_by_hour_day['Rank'] = risk_by_hour_day['Risk_Score'].rank(method='dense', ascending=False).astype(int)\n",
    "\n",
    "\n",
    "print(\"\\n\\n--- 30-DAY DEPLOYMENT RISK ANALYSIS & RECOMMENDATIONS ---\")\n",
    "\n",
    "print(\"\\n[A] GLOBAL MINIMUM RISK DEPLOYMENT WINDOW (The Absolute Safest Hour)\")\n",
    "print(f\"Date/Time: {min_risk_hour['ds']}\")\n",
    "print(f\"Day of Week: {min_risk_hour['Day_of_Week']}\")\n",
    "print(f\"Predicted Impact (Norm): {min_risk_hour['yhat']:,.4f}\")\n",
    "print(f\"Minimum Risk Score: {min_risk_hour['Risk_Score']:,.4f}\")\n",
    "print(\"This is the hour with the lowest combination of predicted traffic and uncertainty in the entire month.\")\n",
    "\n",
    "\n",
    "print(\"\\n[B] GLOBAL MAXIMUM RISK DEPLOYMENT WINDOW (The Absolute Riskiest Hour)\")\n",
    "print(f\"Date/Time: {max_risk_hour['ds']}\")\n",
    "print(f\"Day of Week: {max_risk_hour['Day_of_Week']}\")\n",
    "print(f\"Predicted Impact (Norm): {max_risk_hour['yhat']:,.4f}\")\n",
    "print(f\"Maximum Risk Score: {max_risk_hour['Risk_Score']:,.4f}\")\n",
    "print(\"Deploying during this hour carries the highest combined traffic and uncertainty risk.\")\n",
    "\n",
    "\n",
    "print(\"\\n[C] TOP 5 LOW-RISK DEPLOYMENT WINDOWS (Next Best Suggestions)\")\n",
    "print(\"Based on the 60:40 weighted impact score (normalized 0 to 1).\")\n",
    "print(recommendations.to_markdown(index=False, floatfmt='.4f'))\n",
    "\n",
    "print(\"\\n[D] RISK ANALYSIS BY DATE OF MONTH (Where 1 is the riskiest day - Mean Risk)\")\n",
    "# Add rank for easy interpretation\n",
    "risk_by_month_day['Rank'] = risk_by_month_day['Risk_Score'].rank(method='dense', ascending=False).astype(int)\n",
    "print(risk_by_month_day[['Rank', 'Day_of_Month', 'Risk_Score']].head(5).to_markdown(index=False, floatfmt='.4f'))\n",
    "\n",
    "print(\"\\n[E] RISK ANALYSIS BY DAY OF WEEK (Where 1 is the riskiest day - Mean Risk)\")\n",
    "risk_by_day_of_week['Rank'] = risk_by_day_of_week['Risk_Score'].rank(method='dense', ascending=False).astype(int)\n",
    "# Reorder days for better readability\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "risk_by_day_of_week['Day_of_Week'] = pd.Categorical(risk_by_day_of_week['Day_of_Week'], categories=day_order, ordered=True)\n",
    "risk_by_day_of_week = risk_by_day_of_week.sort_values('Day_of_Week')\n",
    "print(risk_by_day_of_week[['Rank', 'Day_of_Week', 'Risk_Score']].to_markdown(index=False, floatfmt='.4f'))\n",
    "\n",
    "print(\"\\n[F] RISK ANALYSIS BY HOUR OF DAY (Where 1 is the riskiest hour - Mean Risk)\")\n",
    "risk_by_hour['Rank'] = risk_by_hour['Risk_Score'].rank(method='dense', ascending=False).astype(int)\n",
    "print(risk_by_hour[['Rank', 'Hour', 'Risk_Score']].to_markdown(index=False, floatfmt='.4f'))\n",
    "\n",
    "print(\"\\n[G] RISK ANALYSIS BY HOUR AND DAY COMBINED (Where 1 is the riskiest window - Mean Risk)\")\n",
    "print(\"This table ranks all 168 weekly hourly windows (Day + Hour) by their average risk score.\")\n",
    "risk_by_hour_day_safe = risk_by_hour_day.sort_values('Risk_Score', ascending=True).reset_index(drop=True)\n",
    "risk_by_hour_day_risky = risk_by_hour_day.sort_values('Risk_Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Reorder days for display\n",
    "day_order_display = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "risk_by_hour_day_risky['Day_of_Week'] = pd.Categorical(risk_by_hour_day_risky['Day_of_Week'], categories=day_order_display, ordered=True)\n",
    "risk_by_hour_day_safe['Day_of_Week'] = pd.Categorical(risk_by_hour_day_safe['Day_of_Week'], categories=day_order_display, ordered=True)\n",
    "\n",
    "\n",
    "print(\"\\nTop 10 Riskiest Windows:\")\n",
    "print(risk_by_hour_day_risky.head(10)[['Rank', 'Day_of_Week', 'Hour', 'Risk_Score']].to_markdown(index=False, floatfmt='.4f'))\n",
    "\n",
    "print(\"\\nTop 10 Safest Windows:\")\n",
    "print(risk_by_hour_day_safe.head(10)[['Rank', 'Day_of_Week', 'Hour', 'Risk_Score']].to_markdown(index=False, floatfmt='.4f'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
